{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "from datetime import date as pdate\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.abspath(\"data/hist_data.xlsm\")\n",
    "notional_stock = 1000000\n",
    "notional_swap = 100000000\n",
    "swap_rate = 0.042\n",
    "day_count_frac = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_swap_data(file_path):\n",
    "    \"\"\"\n",
    "    read SOFR curve data from excel file \n",
    "\n",
    "    Args:\n",
    "    file_path(str): path to the excel file\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: preprocessed SOFR curve data\n",
    "    \"\"\"\n",
    "    df_sofr_curve_raw = pd.read_excel(file_path, sheet_name=\"SofrCurve\", engine = 'openpyxl', parse_dates=False)\n",
    "    # clean up column names (timestamp)\n",
    "    df_sofr_curve_raw.columns = [str(col) for col in df_sofr_curve_raw.columns]\n",
    "    df_sofr_curve_raw.columns = [col.split()[0] if '-' in col else col for col in df_sofr_curve_raw.columns]\n",
    "    df_sofr_curve_raw.drop(columns=['Tenor'], inplace=True)\n",
    "    df_sofr_curve_raw['T'] = df_sofr_curve_raw['T'].astype(int) # convert T to int\n",
    "    # extract out relevant zero curves (1Y-10Y)\n",
    "    df_sofr_curve = df_sofr_curve_raw.iloc[6:16].copy()\n",
    "    \n",
    "    return df_sofr_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stocks_data(file_path):\n",
    "    \"\"\"\n",
    "    read stock data from excel file\n",
    "\n",
    "    Args:\n",
    "    file_path(str): path to the excel file\n",
    "\n",
    "    Returns: \n",
    "    pd.DataFrame: preprocessed stock data\n",
    "    \"\"\"\n",
    "    sheet_names = [\"AAPL\", \"MSFT\", \"F\", \"BAC\"]\n",
    "    df_stocks = {}\n",
    "    # read stock data in sheet names lst \n",
    "    for sheet_name in sheet_names:\n",
    "        df_stocks[sheet_name] = pd.read_excel(file_path, sheet_name=sheet_name, engine = 'openpyxl', parse_dates=False)\n",
    "        # rename columns in sheet to avoid dupes \n",
    "        df_stocks[sheet_name].rename(columns = {\"Adj Close\": f\"Adj Close_{sheet_name}\"}, inplace = True)\n",
    "    # merge stock data into dataframe based on date\n",
    "    df_stocks_merged = pd.merge(df_stocks[\"AAPL\"], df_stocks[\"MSFT\"], on=\"Date\", how=\"inner\")\n",
    "    df_stocks_merged = pd.merge(df_stocks_merged, df_stocks[\"F\"], on=\"Date\", how=\"inner\")\n",
    "    df_stocks_merged = pd.merge(df_stocks_merged, df_stocks[\"BAC\"], on=\"Date\", how=\"inner\")\n",
    "\n",
    "    df_stocks_merged['Date'] = pd.to_datetime(df_stocks_merged['Date'])\n",
    "\n",
    "    # calculate relative return for each stock\n",
    "    for col in df_stocks_merged.columns:\n",
    "        if \"Adj Close\" in col:  # Apply only to price columns\n",
    "            df_stocks_merged[f\"Return_{col.split('_')[-1]}\"] = df_stocks_merged[col].pct_change()\n",
    "    \n",
    "    df_stocks_merged = df_stocks_merged.iloc[:,5:] # filter returns only\n",
    "    df_stocks_merged = df_stocks_merged.iloc[1:] # remove the first row since it is NaN\n",
    "\n",
    "    return df_stocks_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discount_curve(zero_rates, tenors):\n",
    "    \"\"\"\n",
    "    discount factors based on zero rates\n",
    "\n",
    "    Args:\n",
    "    zero_rates(list): list of zero rates\n",
    "    tenors(list): list of tenors\n",
    "\n",
    "    Returns:\n",
    "    np.array: discount factors\n",
    "    \"\"\"\n",
    "    assert len(zero_rates) == len(tenors), f\"Expect {len(tenors)} zero rates, got {len(zero_rates)}.\"\n",
    "    Z = np.array(zero_rates)\n",
    "    T = np.array(tenors)\n",
    "    return np.exp(-Z*T)\n",
    "\n",
    "\n",
    "def get_forward_curve(zero_rates, tenors, day_count_frac=1):\n",
    "    \"\"\"\n",
    "    forward rates based on zero rates\n",
    "\n",
    "    Args:\n",
    "    zero_rates(list): list of zero rates\n",
    "    tenors(list): list of tenors\n",
    "    day_count_frac(float): day count fraction   \n",
    "\n",
    "    Returns:\n",
    "    np.array: forward rates\n",
    "    \"\"\"\n",
    "    DF = get_discount_curve(zero_rates, tenors)\n",
    "    DF_start = np.concatenate([[1], DF[:-1]]) # first DF=1. we dont consider forward swap here\n",
    "    DF_end = DF\n",
    "    F = (DF_start - DF_end) / (DF_end * day_count_frac)\n",
    "    return F\n",
    "    \n",
    "\n",
    "def get_payer_swap_pv(zero_rates, tenors, forward_rates=None, swap_rate=0.042, day_count_frac=1, notional=100000000):\n",
    "    \"\"\"\n",
    "    calculate the present value of a payer swap\n",
    "\n",
    "    Args:\n",
    "    zero_rates(list): list of zero rates\n",
    "    tenors(list): list of tenors\n",
    "    forward_rates(list): list of forward rates\n",
    "    swap_rate(float): fixed swap rate\n",
    "    day_count_frac(float): day count fraction\n",
    "    notional(float): notional amount\n",
    "\n",
    "    Returns:\n",
    "    float: present value of a swap\n",
    "    \"\"\"\n",
    "    DF = get_discount_curve(zero_rates, tenors)\n",
    "    F = get_forward_curve(zero_rates, tenors) if forward_rates is None else np.array(forward_rates)\n",
    "    pv_fix = swap_rate*sum(day_count_frac*DF)\n",
    "    pv_flt = sum(day_count_frac*F*DF)\n",
    "    return notional*(pv_flt - pv_fix)\n",
    "\n",
    "\n",
    "def swap_pnl_1d_full(zero_rates_t0, zero_rates_t1, tenors):\n",
    "    \"\"\"\n",
    "    1d PNL of swap - full revaluation\n",
    "\n",
    "    Args:\n",
    "    zero_rates_t0(list): list of zero rates at t0 (current zero rates)\n",
    "    zero_rates_t1(list): list of zero rates at t1 (previous historical zero rates)\n",
    "    tenors(list): list of tenors\n",
    "\n",
    "    Returns:\n",
    "    float: 1d PNL of swap\n",
    "    \"\"\"\n",
    "\n",
    "    pv_t0 = get_payer_swap_pv(zero_rates_t0, tenors)\n",
    "    pv_t1 = get_payer_swap_pv(zero_rates_t1, tenors)\n",
    "    return pv_t1 - pv_t0\n",
    "\n",
    "\n",
    "def swap_pnl_1d_sens(zero_rates_t0, zero_rates_chng, tenors, swap_rate = 0.042, notional=100*1000000):\n",
    "    \"\"\"\n",
    "    1d PNL of swap - sensitivity based approach\n",
    "\n",
    "    Args:\n",
    "    zero_rates_t0(list): list of zero rates at t0 \n",
    "    zero_rates_chng(list): list of zero rates change\n",
    "    tenors(list): list of tenors\n",
    "    swap_rate(float): fixed swap rate\n",
    "    notional(float): notional amount\n",
    "\n",
    "    Returns:\n",
    "    float: 1d PNL of swap\n",
    "    \"\"\" \n",
    "    zero_rates_chng = np.array(zero_rates_chng)\n",
    "    tenors = np.array(tenors)\n",
    "    DF_t0 = get_discount_curve(zero_rates_t0, tenors) # exponential discount factor\n",
    "    W = (notional * swap_rate * tenors * DF_t0)# weight of risk factors in PnL sensitivity\n",
    "    W[-1] = notional * (1+swap_rate) * tenors[-1] * DF_t0[-1]\n",
    "    return W @ zero_rates_chng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stocks_merged = get_stocks_data(file_path)\n",
    "df_sofr_curve = get_swap_data(file_path)\n",
    "df_sofr_curve.set_index(df_sofr_curve.iloc[:,0].values)\n",
    "ten_year_sofr_curve = df_sofr_curve.drop(columns=[\"T\"]).T\n",
    "ten_year_sofr_curve.columns = df_sofr_curve['T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenors = df_sofr_curve.iloc[:,0].values\n",
    "sofr_curve_t0 = ten_year_sofr_curve.iloc[-1]\n",
    "pct_change_sofr_rates = ten_year_sofr_curve.diff().dropna().values\n",
    "\n",
    "swap_hist_full_pnl = []\n",
    "swap_hist_sensi_pnl = []\n",
    "\n",
    "for current_sofr_curve in pct_change_sofr_rates:\n",
    "    zero_rates_delta = np.array(current_sofr_curve)\n",
    "    zero_rates_t1 = np.array(sofr_curve_t0) + zero_rates_delta\n",
    "    pnl_full_evaulation = swap_pnl_1d_full(\n",
    "        zero_rates_t0=sofr_curve_t0,\n",
    "        zero_rates_t1=zero_rates_t1,\n",
    "        tenors=tenors\n",
    "    )\n",
    "    pnl_swap_evaluation = swap_pnl_1d_sens(\n",
    "        zero_rates_t0=sofr_curve_t0,\n",
    "        zero_rates_chng=zero_rates_delta,\n",
    "        tenors=tenors\n",
    "    )\n",
    "    swap_hist_full_pnl.append(pnl_full_evaulation)\n",
    "    swap_hist_sensi_pnl.append(pnl_swap_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stocks full revaluation 1d pnl evaluation \n",
    "def stocks_pnl1d_full(stocks_returns, w = [1e6, 1e6, 1e6, 1e6]):\n",
    "    \"\"\"\n",
    "    stocks_returns: DataFrame of stocks returns\n",
    "    w: list of notional weights\n",
    "    \"\"\"\n",
    "    return (w[0]*((1+stocks_returns[0])-1) + w[1]*((1+stocks_returns[1])-1) + w[2]*((1+stocks_returns[2])-1) + w[3]*((1+stocks_returns[3])-1))\n",
    "\n",
    "# stocks sensitivity based 1d pnl evaluation \n",
    "def stocks_pnl1d_sensi(stocks_returns, w = [1e6, 1e6, 1e6, 1e6]):\n",
    "    \"\"\"\n",
    "    stocks_returns: DataFrame of stocks returns\n",
    "    w: list of notional weights\n",
    "    \"\"\"\n",
    "    return stocks_returns @ w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================================================================================================================\n",
      "Historical VaR:\n",
      "VaR [1d, 95%], Full Revaluation: 966,173\n",
      "VaR [1d, 95%], Sensitivity: 972,734\n",
      "============================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# historical VaR\n",
    "confidence_level = 95\n",
    "\n",
    "stocks_pnl1d_full_hist = [stocks_pnl1d_full(s) for s in df_stocks_merged.values]   \n",
    "stocks_pnl1d_sensi_hist = [stocks_pnl1d_sensi(s) for s in df_stocks_merged.values]\n",
    "\n",
    "pnl1d_full_hist = np.array(stocks_pnl1d_full_hist) + np.array(swap_hist_full_pnl)\n",
    "var1d_full_hist = np.abs(np.percentile(pnl1d_full_hist, 100-confidence_level))\n",
    "\n",
    "pnl1d_sensi_hist = np.array(stocks_pnl1d_sensi_hist) + (np.array(swap_hist_sensi_pnl).reshape(-1,1)) \n",
    "var1d_sensi_hist = np.abs(np.percentile(pnl1d_sensi_hist, 100-confidence_level))\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"============================================================================================================================\")\n",
    "print(\"Historical VaR:\")\n",
    "print(f\"VaR [1d, {confidence_level}%], Full Revaluation: {var1d_full_hist:,.0f}\") \n",
    "print(f\"VaR [1d, {confidence_level}%], Sensitivity: {var1d_sensi_hist:,.0f}\") \n",
    "print(\"============================================================================================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
